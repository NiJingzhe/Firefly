"""
å±å¹•æˆªå›¾å·¥å…·
æä¾›å±å¹•æˆªå›¾åŠŸèƒ½ï¼Œæ”¯æŒå…¨å±æˆ–æŒ‡å®šåŒºåŸŸæˆªå›¾
"""

import os
import tempfile
import json
import numpy as np
from typing import Optional, Tuple, List, Dict, Any
from SimpleLLMFunc.tool import tool
from SimpleLLMFunc.llm_decorator.multimodal_types import ImgPath
from paddleocr import PaddleOCR
from config.config import get_config
from PIL import Image, ImageDraw, ImageFont
from .common import print_tool_output

config = get_config()   

try:
    import pyautogui
    from PIL import ImageGrab
    SCREENSHOT_AVAILABLE = True
except ImportError:
    SCREENSHOT_AVAILABLE = False


ocr = PaddleOCR(
    text_detection_model_dir=config.PPOCR_DET_MODEL_DIR,
    text_recognition_model_dir=config.PPOCR_REC_MODEL_DIR,
    text_detection_model_name="PP-OCRv5_mobile_det",
    text_recognition_model_name="PP-OCRv5_mobile_rec",
    use_doc_orientation_classify=False,
    use_doc_unwarping=False,
    use_textline_orientation=False,
) # æ›´æ¢ PP-OCRv5_server æ¨¡å‹



@tool(name="capture_screen", description="æˆªå–å±å¹•æˆªå›¾")
def capture_screen() -> str:
    """
    æˆªå–å±å¹•æˆªå›¾å¹¶è¿”å›å›¾ç‰‡è·¯å¾„
        
    Returns:
        æˆªå›¾æ–‡ä»¶çš„è·¯å¾„
        
    Raises:
        RuntimeError: å½“æˆªå›¾åŠŸèƒ½ä¸å¯ç”¨æ—¶æŠ›å‡º
    """
    if not SCREENSHOT_AVAILABLE:
        raise RuntimeError("å±å¹•æˆªå›¾åŠŸèƒ½ä¸å¯ç”¨ã€‚è¯·å®‰è£…ä¾èµ–ï¼špip install pyautogui pillow")
    
    try:
        screenshot = ImageGrab.grab()
        
        # ä¿æŒæ¯”ä¾‹çš„ç¼©æ”¾åˆ°1080p
        width, height = screenshot.size
        target_width = 1920
        target_height = int((target_width / width) * height)    
        
        screenshot = screenshot.resize((target_width, target_height), Image.Resampling.LANCZOS)    
     
        # ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶
        temp_file = tempfile.NamedTemporaryFile(
            delete=False, 
            suffix='.png', 
            prefix='screenshot_'
        )
        file_path = temp_file.name
        temp_file.close()
        
        # ä¿å­˜æˆªå›¾
        screenshot.save(file_path, 'PNG')

        print_tool_output(title="æˆªå›¾ä¿å­˜æˆåŠŸ", content=f"ğŸ“· æˆªå›¾å·²ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶: {file_path}, å¼€å§‹OCRè¯†åˆ«")

        # ä½¿ç”¨predict_iterç”Ÿæˆå™¨æ–¹å¼å®ç°è¾¹è¯†åˆ«è¾¹å¤„ç†
        result_iter = ocr.predict_iter(file_path)
        
        # å¤„ç†OCRç»“æœ
        processed_result = _process_ocr_result_iter(result_iter, file_path)

        print_tool_output(title="OCRè¯†åˆ«å®Œæˆ", content="å¤„ç†ç»“æœå¦‚ä¸‹ï¼š")
        print_tool_output(title="OCRè¯†åˆ«ç»“æœ", content=processed_result["text_result"])

        return processed_result["text_result"]
        
    except Exception as e:
        raise RuntimeError(f"æˆªå›¾å¤±è´¥: {str(e)}") from e


def _calculate_bbox_area(bbox: np.ndarray) -> float:
    """è®¡ç®—è¾¹ç•Œæ¡†é¢ç§¯"""
    # bboxæ ¼å¼: [[x1, y1], [x2, y2], [x3, y3], [x4, y4]]
    # ä½¿ç”¨å‘é‡å‰ç§¯è®¡ç®—å¤šè¾¹å½¢é¢ç§¯
    x = bbox[:, 0]
    y = bbox[:, 1]
    return 0.5 * abs(sum(x[i] * y[i + 1] - x[i + 1] * y[i] for i in range(-1, len(x) - 1)))


def _get_bbox_top_left(bbox: np.ndarray) -> Tuple[int, int]:
    """è·å–è¾¹ç•Œæ¡†å·¦ä¸Šè§’åæ ‡"""
    x_min = int(np.min(bbox[:, 0]))
    y_min = int(np.min(bbox[:, 1]))
    return x_min, y_min


def _process_ocr_result(ocr_result_list, original_image_path: str) -> Dict[str, Any]:
    """
    å¤„ç†OCRç»“æœï¼š
    1. æ‰¾åˆ°æ–‡æœ¬å’Œbounding boxçš„å¯¹åº”å…³ç³»
    2. æŒ‰bboxé¢ç§¯ä»å¤§åˆ°å°æ’åº
    3. é€‰å–å‰50%çš„ç»“æœ
    4. ç»˜åˆ¶æ ‡æ³¨å›¾åƒå’Œç”ŸæˆJSONç»“æœ
    """
    # OCRç»“æœæ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼Œéå†æ‰€æœ‰ç»“æœ
    if not ocr_result_list:
        return {
            "text_result": "OCRæœªè¯†åˆ«åˆ°ä»»ä½•æ–‡æœ¬",
            "image_path": original_image_path
        }
    
    # æ”¶é›†æ‰€æœ‰OCRç»“æœä¸­çš„æ–‡æœ¬å’Œè¾¹ç•Œæ¡†
    all_texts = []
    all_polys = []
    all_scores = []
    
    for ocr_result in ocr_result_list:
        # è·å–OCRç»“æœçš„JSONæ•°æ®
        ocr_json = ocr_result.json
        
        # ä» 'res' å­—æ®µä¸­æå–å®é™…ç»“æœ
        res_data = ocr_json.get('res', {})
        
        # æå–æ–‡æœ¬ã€è¾¹ç•Œæ¡†å’Œç½®ä¿¡åº¦
        rec_texts = res_data.get('rec_texts', [])
        rec_polys = res_data.get('rec_polys', [])
        rec_scores = res_data.get('rec_scores', [])
        
        # åˆå¹¶åˆ°æ€»åˆ—è¡¨ä¸­
        all_texts.extend(rec_texts)
        all_polys.extend(rec_polys)
        all_scores.extend(rec_scores)
    
    if not all_texts or not all_polys:
        return {
            "text_result": "OCRæœªè¯†åˆ«åˆ°ä»»ä½•æ–‡æœ¬",
            "image_path": original_image_path
        }
    
    # åˆ›å»ºæ–‡æœ¬-è¾¹ç•Œæ¡†å¯¹åº”å…³ç³»åˆ—è¡¨
    text_bbox_pairs = []
    for i, (text, bbox_list, score) in enumerate(zip(all_texts, all_polys, all_scores)):
        # å°†åˆ—è¡¨è½¬æ¢ä¸ºnumpyæ•°ç»„
        bbox = np.array(bbox_list, dtype=np.int32)
        area = _calculate_bbox_area(bbox)
        top_left = _get_bbox_top_left(bbox)
        
        text_bbox_pairs.append({
            'index': i,
            'text': text,
            'bbox': bbox,
            'area': area,
            'top_left': top_left,
            'score': score
        })
    
    # åˆå¹¶ç›¸è¿‘çš„è¾¹ç•Œæ¡†
    print_tool_output(title="è¾¹ç•Œæ¡†åˆå¹¶", content=f"åˆå¹¶å‰æœ‰ {len(text_bbox_pairs)} ä¸ªæ–‡æœ¬æ¡†")
    merged_pairs = _merge_nearby_bboxes(text_bbox_pairs, distance_threshold=80.0)
    print_tool_output(title="è¾¹ç•Œæ¡†åˆå¹¶å®Œæˆ", content=f"åˆå¹¶åæœ‰ {len(merged_pairs)} ä¸ªæ–‡æœ¬æ¡†")
    
    # æŒ‰ä½ç½®æ’åºï¼šå…ˆæŒ‰Yåæ ‡ï¼ˆä»ä¸Šåˆ°ä¸‹ï¼‰ï¼Œå†æŒ‰Xåæ ‡ï¼ˆä»å·¦åˆ°å³ï¼‰
    merged_pairs.sort(key=lambda x: (x['top_left'][1], x['top_left'][0]))
    
    # é€‰å–å‰50%çš„ç»“æœï¼ˆæŒ‰é¢ç§¯ï¼‰
    merged_pairs_by_area = sorted(merged_pairs, key=lambda x: x['area'], reverse=True)
    top_50_percent = merged_pairs_by_area[:max(1, len(merged_pairs_by_area) // 3)]
    
    # å°†é€‰ä¸­çš„ç»“æœé‡æ–°æŒ‰ä½ç½®æ’åº
    top_50_percent.sort(key=lambda x: (x['top_left'][1], x['top_left'][0]))
    
    # ç”Ÿæˆæ ‡æ³¨å›¾åƒ
    annotated_image_path = _create_annotated_image(original_image_path, top_50_percent)
    
    # ç”ŸæˆJSONç»“æœ
    json_result = []
    for i, item in enumerate(top_50_percent, 1):
        json_result.append({
            'id': i,
            'text': item['text'],
            'top_left_x': item['top_left'][0],
            'top_left_y': item['top_left'][1],
            'area': item['area'],
            'confidence': item['score']
        })
    
    # æ„é€ æ–‡æœ¬ç»“æœ
    text_result = f"OCRè¯†åˆ«ç»“æœï¼ˆå‰50%ï¼Œå…±{len(top_50_percent)}ä¸ªï¼‰:\n"
    text_result += json.dumps(json_result, ensure_ascii=False, indent=2)
    
    return {
        "text_result": text_result,
        "image_path": annotated_image_path
    }


def _process_ocr_result_iter(ocr_result_iter, original_image_path: str) -> Dict[str, Any]:
    """
    å¤„ç†OCRè¿­ä»£å™¨ç»“æœï¼š
    1. è¾¹è¯†åˆ«è¾¹å¤„ç†ï¼Œé€æ­¥æ”¶é›†æ–‡æœ¬å’Œbounding box
    2. æŒ‰bboxé¢ç§¯ä»å¤§åˆ°å°æ’åº
    3. é€‰å–å‰50%çš„ç»“æœ
    4. ç»˜åˆ¶æ ‡æ³¨å›¾åƒå’Œç”ŸæˆJSONç»“æœ
    """
    # æ”¶é›†æ‰€æœ‰OCRç»“æœä¸­çš„æ–‡æœ¬å’Œè¾¹ç•Œæ¡†
    all_texts = []
    all_polys = []
    all_scores = []
    
    print_tool_output(title="OCRè¯†åˆ«", content="å¼€å§‹é€æ­¥å¤„ç†OCRç»“æœ...")
    
    # ä½¿ç”¨è¿­ä»£å™¨é€æ­¥å¤„ç†ç»“æœ
    try:
        for i, ocr_result in enumerate(ocr_result_iter):
            # è·å–OCRç»“æœçš„JSONæ•°æ®
            ocr_json = ocr_result.json
            
            # ä» 'res' å­—æ®µä¸­æå–å®é™…ç»“æœ
            res_data = ocr_json.get('res', {})
            
            # æå–æ–‡æœ¬ã€è¾¹ç•Œæ¡†å’Œç½®ä¿¡åº¦
            rec_texts = res_data.get('rec_texts', [])
            rec_polys = res_data.get('rec_polys', [])
            rec_scores = res_data.get('rec_scores', [])
            
            # åˆå¹¶åˆ°æ€»åˆ—è¡¨ä¸­
            all_texts.extend(rec_texts)
            all_polys.extend(rec_polys)
            all_scores.extend(rec_scores)
            
            # æ˜¾ç¤ºå¤„ç†è¿›åº¦
            if rec_texts:
                print_tool_output(title=f"å¤„ç†æ‰¹æ¬¡{i+1}", content=f"è¯†åˆ«åˆ° {len(rec_texts)} ä¸ªæ–‡æœ¬")
    
    except Exception as e:
        print_tool_output(title="OCRå¤„ç†è­¦å‘Š", content=f"è¿­ä»£å™¨å¤„ç†å‡ºç°å¼‚å¸¸: {str(e)}")
        # å¦‚æœè¿­ä»£å™¨å‡ºç°é—®é¢˜ï¼Œç»§ç»­å¤„ç†å·²æ”¶é›†çš„ç»“æœ
    
    if not all_texts or not all_polys:
        return {
            "text_result": "OCRæœªè¯†åˆ«åˆ°ä»»ä½•æ–‡æœ¬",
            "image_path": original_image_path
        }
    
    print_tool_output(title="OCRè¯†åˆ«å®Œæˆ", content=f"æ€»å…±è¯†åˆ«åˆ° {len(all_texts)} ä¸ªæ–‡æœ¬")
    
    # åˆ›å»ºæ–‡æœ¬-è¾¹ç•Œæ¡†å¯¹åº”å…³ç³»åˆ—è¡¨
    text_bbox_pairs = []
    for i, (text, bbox_list, score) in enumerate(zip(all_texts, all_polys, all_scores)):
        # å°†åˆ—è¡¨è½¬æ¢ä¸ºnumpyæ•°ç»„
        bbox = np.array(bbox_list, dtype=np.int32)
        area = _calculate_bbox_area(bbox)
        top_left = _get_bbox_top_left(bbox)
        
        text_bbox_pairs.append({
            'index': i,
            'text': text,
            'bbox': bbox,
            'area': area,
            'top_left': top_left,
            'score': score
        })
    
    # åˆå¹¶ç›¸è¿‘çš„è¾¹ç•Œæ¡†
    print_tool_output(title="è¾¹ç•Œæ¡†åˆå¹¶", content=f"åˆå¹¶å‰æœ‰ {len(text_bbox_pairs)} ä¸ªæ–‡æœ¬æ¡†")
    merged_pairs = _merge_nearby_bboxes(text_bbox_pairs, distance_threshold=80.0)
    print_tool_output(title="è¾¹ç•Œæ¡†åˆå¹¶å®Œæˆ", content=f"åˆå¹¶åæœ‰ {len(merged_pairs)} ä¸ªæ–‡æœ¬æ¡†")
    
    # æŒ‰ä½ç½®æ’åºï¼šå…ˆæŒ‰Yåæ ‡ï¼ˆä»ä¸Šåˆ°ä¸‹ï¼‰ï¼Œå†æŒ‰Xåæ ‡ï¼ˆä»å·¦åˆ°å³ï¼‰
    merged_pairs.sort(key=lambda x: (x['top_left'][1], x['top_left'][0]))
    
    # é€‰å–å‰50%çš„ç»“æœï¼ˆæŒ‰é¢ç§¯ï¼‰
    merged_pairs_by_area = sorted(merged_pairs, key=lambda x: x['area'], reverse=True)
    top_50_percent = merged_pairs_by_area[:max(1, len(merged_pairs_by_area) // 4)]
    
    # å°†é€‰ä¸­çš„ç»“æœé‡æ–°æŒ‰ä½ç½®æ’åº
    top_50_percent.sort(key=lambda x: (x['top_left'][1], x['top_left'][0]))
    
    # ç”Ÿæˆæ ‡æ³¨å›¾åƒ
    annotated_image_path = _create_annotated_image(original_image_path, top_50_percent)
    
    # ç”ŸæˆJSONç»“æœ
    json_result = []
    for i, item in enumerate(top_50_percent, 1):
        json_result.append({
            'id': i,
            'text': item['text'],
            'top_left_x': item['top_left'][0],
            'top_left_y': item['top_left'][1],
            'area': item['area'],
            'confidence': item['score']
        })
    
    # æ„é€ æ–‡æœ¬ç»“æœ
    text_result = f"OCRè¯†åˆ«ç»“æœï¼ˆå‰50%ï¼Œå…±{len(top_50_percent)}ä¸ªï¼‰:\n"
    text_result += json.dumps(json_result, ensure_ascii=False, indent=2)
    
    return {
        "text_result": text_result,
        "image_path": annotated_image_path
    }


def _create_annotated_image(original_image_path: str, text_bbox_pairs: List[Dict]) -> str:
    """åˆ›å»ºå¸¦æ ‡æ³¨çš„å›¾åƒ"""
    # æ‰“å¼€åŸå§‹å›¾åƒ
    image = Image.open(original_image_path)
    draw = ImageDraw.Draw(image)
    
    # å°è¯•åŠ è½½å­—ä½“ï¼Œå¦‚æœå¤±è´¥åˆ™ä½¿ç”¨é»˜è®¤å­—ä½“
    try:
        # åœ¨macOSä¸Šå°è¯•åŠ è½½ç³»ç»Ÿå­—ä½“
        font = ImageFont.truetype("/System/Library/Fonts/PingFang.ttc", 24)
    except:
        try:
            font = ImageFont.truetype("/System/Library/Fonts/Arial.ttf", 24)
        except:
            font = ImageFont.load_default()
    
    # ç»˜åˆ¶è¾¹ç•Œæ¡†å’Œæ ‡å·
    for i, item in enumerate(text_bbox_pairs, 1):
        bbox = item['bbox']
        
        # ç»˜åˆ¶è¾¹ç•Œæ¡†
        # å°†bboxè½¬æ¢ä¸ºPILå¯ç”¨çš„æ ¼å¼
        bbox_points = [(int(point[0]), int(point[1])) for point in bbox]
        draw.polygon(bbox_points, outline='red', width=2)
        
        # åœ¨å·¦ä¸Šè§’ç»˜åˆ¶æ ‡å·
        top_left = item['top_left']
        
        # ç»˜åˆ¶æ ‡å·èƒŒæ™¯
        text_bbox = draw.textbbox((top_left[0], top_left[1] - 30), str(i), font=font)
        draw.rectangle(text_bbox, fill='red')
        
        # ç»˜åˆ¶æ ‡å·æ–‡å­—
        draw.text((top_left[0], top_left[1] - 30), str(i), fill='white', font=font)
    
    # ä¿å­˜æ ‡æ³¨å›¾åƒ
    annotated_file = tempfile.NamedTemporaryFile(
        delete=False,
        suffix='_annotated.png',
        prefix='screenshot_'
    )
    annotated_path = annotated_file.name
    annotated_file.close()
    
    image.save(annotated_path, 'PNG')
    return annotated_path


def _calculate_bbox_distance(bbox1: np.ndarray, bbox2: np.ndarray) -> float:
    """è®¡ç®—ä¸¤ä¸ªè¾¹ç•Œæ¡†çš„æœ€å°è·ç¦»"""
    # è·å–ä¸¤ä¸ªè¾¹ç•Œæ¡†çš„ä¸­å¿ƒç‚¹
    center1 = np.mean(bbox1, axis=0)
    center2 = np.mean(bbox2, axis=0)
    
    # è®¡ç®—è¾¹ç•Œæ¡†çš„æœ€å°å¤–æ¥çŸ©å½¢
    x1_min, y1_min = np.min(bbox1, axis=0)
    x1_max, y1_max = np.max(bbox1, axis=0)
    x2_min, y2_min = np.min(bbox2, axis=0)
    x2_max, y2_max = np.max(bbox2, axis=0)
    
    # è®¡ç®—çŸ©å½¢é—´çš„è·ç¦»
    dx = max(0, max(x1_min - x2_max, x2_min - x1_max))
    dy = max(0, max(y1_min - y2_max, y2_min - y1_max))
    
    return np.sqrt(dx*dx + dy*dy)


def _merge_bboxes(bbox1: np.ndarray, bbox2: np.ndarray) -> np.ndarray:
    """åˆå¹¶ä¸¤ä¸ªè¾¹ç•Œæ¡†ï¼Œè¿”å›åŒ…å«ä¸¤è€…çš„æœ€å°è¾¹ç•Œæ¡†"""
    all_points = np.vstack([bbox1, bbox2])
    
    # æ‰¾åˆ°æœ€å°å¤–æ¥çŸ©å½¢çš„å››ä¸ªè§’ç‚¹
    x_min, y_min = np.min(all_points, axis=0)
    x_max, y_max = np.max(all_points, axis=0)
    
    # è¿”å›çŸ©å½¢çš„å››ä¸ªè§’ç‚¹
    return np.array([
        [x_min, y_min],
        [x_max, y_min], 
        [x_max, y_max],
        [x_min, y_max]
    ], dtype=np.int32)


def _is_vertical_merge(bbox1: np.ndarray, bbox2: np.ndarray) -> bool:
    """åˆ¤æ–­ä¸¤ä¸ªè¾¹ç•Œæ¡†æ˜¯å¦åº”è¯¥è¿›è¡Œå‚ç›´æ–¹å‘çš„åˆå¹¶ï¼ˆä¸Šä¸‹æ’åˆ—ï¼‰"""
    # è·å–è¾¹ç•Œæ¡†çš„è¾¹ç•Œå’Œä¸­å¿ƒç‚¹
    y1_min, y1_max = np.min(bbox1[:, 1]), np.max(bbox1[:, 1])
    y2_min, y2_max = np.min(bbox2[:, 1]), np.max(bbox2[:, 1])
    x1_min, x1_max = np.min(bbox1[:, 0]), np.max(bbox1[:, 0])
    x2_min, x2_max = np.min(bbox2[:, 0]), np.max(bbox2[:, 0])
    
    # è®¡ç®—ä¸­å¿ƒç‚¹
    center1_y = (y1_min + y1_max) / 2
    center2_y = (y2_min + y2_max) / 2
    
    # è®¡ç®—é«˜åº¦
    height1 = y1_max - y1_min
    height2 = y2_max - y2_min
    
    # è®¡ç®—å‚ç›´è·ç¦»
    vertical_distance = abs(center1_y - center2_y)
    
    # è®¡ç®—æ°´å¹³é‡å 
    x_overlap = max(0, min(x1_max, x2_max) - max(x1_min, x2_min))
    width1 = x1_max - x1_min
    width2 = x2_max - x2_min
    
    if width1 == 0 or width2 == 0:
        return False
    
    # è®¡ç®—æ°´å¹³é‡å æ¯”ä¾‹ï¼ˆç›¸å¯¹äºä»»ä¸€ä¸ªbboxçš„å®½åº¦ï¼‰
    overlap_ratio1 = x_overlap / width1
    overlap_ratio2 = x_overlap / width2
    max_overlap_ratio = max(overlap_ratio1, overlap_ratio2)
    
    # å‚ç›´åˆå¹¶æ¡ä»¶ï¼š
    # 1. å‚ç›´è·ç¦»å°äºä»»ä¸€bboxé«˜åº¦çš„1.1å€
    # 2. æ°´å¹³é‡å è¶…è¿‡ä»»ä¸€bboxå®½åº¦çš„70%
    height_threshold = max(height1, height2) * 1.1
    
    return (vertical_distance < height_threshold and 
            max_overlap_ratio > 0.3)


def _merge_nearby_bboxes(text_bbox_pairs: List[Dict], distance_threshold: float = 50.0) -> List[Dict]:
    """åˆå¹¶ç›¸è¿‘çš„è¾¹ç•Œæ¡†ï¼ˆä»…å‚ç›´æ–¹å‘ï¼‰"""
    if len(text_bbox_pairs) <= 1:
        return text_bbox_pairs
    
    merged_pairs = []
    used_indices = set()
    
    for i, pair1 in enumerate(text_bbox_pairs):
        if i in used_indices:
            continue
            
        # åˆå§‹åŒ–åˆå¹¶ç»„
        merge_group = [pair1]
        merge_indices = {i}
        
        # æŸ¥æ‰¾éœ€è¦åˆå¹¶çš„è¾¹ç•Œæ¡†ï¼ˆä»…è€ƒè™‘å‚ç›´æ–¹å‘ï¼‰
        for j, pair2 in enumerate(text_bbox_pairs):
            if j in used_indices or j <= i:
                continue
                
            # é¦–å…ˆæ£€æŸ¥æ˜¯å¦ç¬¦åˆå‚ç›´åˆå¹¶æ¡ä»¶
            is_vertical = _is_vertical_merge(pair1['bbox'], pair2['bbox'])
            if not is_vertical:
                continue
                
            # è®¡ç®—ä¸ç»„ä¸­ä»»ä¸€è¾¹ç•Œæ¡†çš„æœ€å°è·ç¦»
            min_distance = float('inf')
            for group_pair in merge_group:
                dist = _calculate_bbox_distance(group_pair['bbox'], pair2['bbox'])
                min_distance = min(min_distance, dist)
            
            # å¦‚æœè·ç¦»å°äºé˜ˆå€¼ä¸”æ˜¯å‚ç›´æ’åˆ—ï¼ŒåŠ å…¥åˆå¹¶ç»„
            if min_distance <= distance_threshold:
                merge_group.append(pair2)
                merge_indices.add(j)
        
        # æ ‡è®°å·²ä½¿ç”¨çš„ç´¢å¼•
        used_indices.update(merge_indices)
        
        if len(merge_group) == 1:
            # æ²¡æœ‰éœ€è¦åˆå¹¶çš„ï¼Œç›´æ¥æ·»åŠ 
            merged_pairs.append(pair1)
        else:
            # åˆå¹¶å¤šä¸ªè¾¹ç•Œæ¡†ï¼ˆæŒ‰Yåæ ‡æ’åºï¼‰
            merge_group_sorted = sorted(merge_group, key=lambda x: np.mean(x['bbox'][:, 1]))
            
            merged_bbox = merge_group_sorted[0]['bbox']
            merged_texts = [merge_group_sorted[0]['text']]
            merged_scores = [merge_group_sorted[0]['score']]
            
            for group_pair in merge_group_sorted[1:]:
                merged_bbox = _merge_bboxes(merged_bbox, group_pair['bbox'])
                merged_texts.append(group_pair['text'])
                merged_scores.append(group_pair['score'])
            
            # åˆ›å»ºåˆå¹¶åçš„é¡¹
            merged_area = _calculate_bbox_area(merged_bbox)
            merged_top_left = _get_bbox_top_left(merged_bbox)
            
            # å‚ç›´åˆå¹¶ç”¨æ¢è¡Œç¬¦è¿æ¥
            merged_text = '\n'.join(merged_texts)
            merged_score = np.mean(merged_scores)  # å¹³å‡ç½®ä¿¡åº¦
            
            merged_pairs.append({
                'index': len(merged_pairs),
                'text': merged_text,
                'bbox': merged_bbox,
                'area': merged_area,
                'top_left': merged_top_left,
                'score': merged_score
            })
    
    return merged_pairs


if __name__ == "__main__":
    """ç®€å•æµ‹è¯•æˆªå›¾å’ŒOCRåŠŸèƒ½"""
    print("å¼€å§‹æµ‹è¯•å±å¹•æˆªå›¾å’ŒOCRåŠŸèƒ½...")
    print("è¯·ç¡®ä¿å±å¹•ä¸Šæœ‰ä¸€äº›æ–‡å­—å†…å®¹ï¼Œæµ‹è¯•å°†åœ¨3ç§’åå¼€å§‹æˆªå›¾")
    
    import time
    
    # ç»™ç”¨æˆ·å‡†å¤‡æ—¶é—´
    for i in range(3, 0, -1):
        print(f"å€’è®¡æ—¶: {i}ç§’")
        time.sleep(1)
    
    try:
        print("æ­£åœ¨æˆªå›¾å¹¶è¿›è¡ŒOCRè¯†åˆ«...")
        text_result, image_path = capture_screen()
        
        print("\n" + "="*50)
        print("OCRè¯†åˆ«ç»“æœ:")
        print("="*50)
        print(text_result)
        print("\n" + "="*50)
        print(f"æ ‡æ³¨å›¾åƒå·²ä¿å­˜åˆ°: {image_path}")
        print("="*50)
        
        # å°è¯•æ‰“å¼€å›¾åƒæŸ¥çœ‹ï¼ˆä»…åœ¨macOSä¸Šï¼‰
        import subprocess
        import sys
        if sys.platform == "darwin":  # macOS
            try:
                subprocess.run(["open", str(image_path)], check=True)
                print("å·²åœ¨é»˜è®¤å›¾åƒæŸ¥çœ‹å™¨ä¸­æ‰“å¼€æ ‡æ³¨å›¾åƒ")
            except subprocess.CalledProcessError:
                print("æ— æ³•è‡ªåŠ¨æ‰“å¼€å›¾åƒï¼Œè¯·æ‰‹åŠ¨æŸ¥çœ‹ä¸Šè¿°è·¯å¾„çš„å›¾åƒæ–‡ä»¶")
        else:
            print("è¯·æ‰‹åŠ¨æŸ¥çœ‹ä¸Šè¿°è·¯å¾„çš„æ ‡æ³¨å›¾åƒæ–‡ä»¶")
            
    except Exception as e:
        print(f"æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


